{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba5bee7-3246-49c4-ba21-888e04bc32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b5e843-7715-4e40-a289-b762d8dc2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "spambase = fetch_ucirepo(id=94)\n",
    "X = spambase.data.features\n",
    "y = spambase.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1998e7-3e40-423b-86c9-18656b165cc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0.00               0.64           0.64           0.0   \n",
       "1               0.21               0.28           0.50           0.0   \n",
       "2               0.06               0.00           0.71           0.0   \n",
       "3               0.00               0.00           0.00           0.0   \n",
       "4               0.00               0.00           0.00           0.0   \n",
       "...              ...                ...            ...           ...   \n",
       "4596            0.31               0.00           0.62           0.0   \n",
       "4597            0.00               0.00           0.00           0.0   \n",
       "4598            0.30               0.00           0.30           0.0   \n",
       "4599            0.96               0.00           0.00           0.0   \n",
       "4600            0.00               0.00           0.65           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0              0.32            0.00              0.00                0.00   \n",
       "1              0.14            0.28              0.21                0.07   \n",
       "2              1.23            0.19              0.19                0.12   \n",
       "3              0.63            0.00              0.31                0.63   \n",
       "4              0.63            0.00              0.31                0.63   \n",
       "...             ...             ...               ...                 ...   \n",
       "4596           0.00            0.31              0.00                0.00   \n",
       "4597           0.00            0.00              0.00                0.00   \n",
       "4598           0.00            0.00              0.00                0.00   \n",
       "4599           0.32            0.00              0.00                0.00   \n",
       "4600           0.00            0.00              0.00                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "0                0.00            0.00  ...                   0.0        0.000   \n",
       "1                0.00            0.94  ...                   0.0        0.000   \n",
       "2                0.64            0.25  ...                   0.0        0.010   \n",
       "3                0.31            0.63  ...                   0.0        0.000   \n",
       "4                0.31            0.63  ...                   0.0        0.000   \n",
       "...               ...             ...  ...                   ...          ...   \n",
       "4596             0.00            0.00  ...                   0.0        0.000   \n",
       "4597             0.00            0.00  ...                   0.0        0.000   \n",
       "4598             0.00            0.00  ...                   0.0        0.102   \n",
       "4599             0.00            0.00  ...                   0.0        0.000   \n",
       "4600             0.00            0.00  ...                   0.0        0.000   \n",
       "\n",
       "      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0           0.000          0.0        0.778        0.000        0.000   \n",
       "1           0.132          0.0        0.372        0.180        0.048   \n",
       "2           0.143          0.0        0.276        0.184        0.010   \n",
       "3           0.137          0.0        0.137        0.000        0.000   \n",
       "4           0.135          0.0        0.135        0.000        0.000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4596        0.232          0.0        0.000        0.000        0.000   \n",
       "4597        0.000          0.0        0.353        0.000        0.000   \n",
       "4598        0.718          0.0        0.000        0.000        0.000   \n",
       "4599        0.057          0.0        0.000        0.000        0.000   \n",
       "4600        0.000          0.0        0.125        0.000        0.000   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "0                          3.756                          61   \n",
       "1                          5.114                         101   \n",
       "2                          9.821                         485   \n",
       "3                          3.537                          40   \n",
       "4                          3.537                          40   \n",
       "...                          ...                         ...   \n",
       "4596                       1.142                           3   \n",
       "4597                       1.555                           4   \n",
       "4598                       1.404                           6   \n",
       "4599                       1.147                           5   \n",
       "4600                       1.250                           5   \n",
       "\n",
       "      capital_run_length_total  \n",
       "0                          278  \n",
       "1                         1028  \n",
       "2                         2259  \n",
       "3                          191  \n",
       "4                          191  \n",
       "...                        ...  \n",
       "4596                        88  \n",
       "4597                        14  \n",
       "4598                       118  \n",
       "4599                        78  \n",
       "4600                        40  \n",
       "\n",
       "[4601 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X is already vectorized\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd14f05a-b3fb-44c1-8bad-a93d6afe94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6201ecb-d6c6-4dce-8093-e6ff1c008de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmodel = LogisticRegression()\n",
    "\n",
    "svmmodel = SVC()\n",
    "\n",
    "nbmodel = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a52801-4d55-46ce-bbab-52369e459b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluvate(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_predicted=model.predict(X_test)\n",
    "    print(model.score(X_test,y_test))\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    print(cm)\n",
    "    print(classification_report(y_test, y_predicted))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6eca360-0029-40d6-8c92-2d136f2ea3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9283387622149837\n",
      "[[527  32]\n",
      " [ 34 328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       559\n",
      "           1       0.91      0.91      0.91       362\n",
      "\n",
      "    accuracy                           0.93       921\n",
      "   macro avg       0.93      0.92      0.92       921\n",
      "weighted avg       0.93      0.93      0.93       921\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premk\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\premk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "evaluvate(lrmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad314787-a7c3-4847-9350-e34a07511e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premk\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7339847991313789\n",
      "[[504  55]\n",
      " [190 172]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.80       559\n",
      "           1       0.76      0.48      0.58       362\n",
      "\n",
      "    accuracy                           0.73       921\n",
      "   macro avg       0.74      0.69      0.69       921\n",
      "weighted avg       0.74      0.73      0.72       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluvate(svmmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "359960ff-1f5f-4aff-a1c5-527ca0963800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8121606948968513\n",
      "[[471  88]\n",
      " [ 85 277]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       559\n",
      "           1       0.76      0.77      0.76       362\n",
      "\n",
      "    accuracy                           0.81       921\n",
      "   macro avg       0.80      0.80      0.80       921\n",
      "weighted avg       0.81      0.81      0.81       921\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premk\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "evaluvate(nbmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f80663e0-5855-4d04-bcb1-1be2df35b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras import Sequential, layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cda6b3a-8ea1-4644-87cb-0611ef3818cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premk\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "model = Sequential([\n",
    "  layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), #not one hot code \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b73c37ee-1187-4358-a67d-96362bdeab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.8813 - loss: 0.4791\n",
      "Epoch 2/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8723 - loss: 0.9095\n",
      "Epoch 3/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9007 - loss: 0.5530\n",
      "Epoch 4/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8946 - loss: 0.3971\n",
      "Epoch 5/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9224 - loss: 0.2430\n",
      "Epoch 6/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8541 - loss: 1.3203\n",
      "Epoch 7/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2921\n",
      "Epoch 8/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8878 - loss: 0.5477\n",
      "Epoch 9/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9246 - loss: 0.2295\n",
      "Epoch 10/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b53288b4d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74e69f56-42b8-4c7c-9432-43a0d8a881df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred=np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "545ae630-69ed-4fc2-9453-be654dad06f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35ce1bce-ba5d-4686-a2b4-ba215004659e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test=y_test.to_numpy() #converting to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1954cade-dbf6-49bd-8169-17ca5e479ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y):\n",
    "    noofcorrect=0\n",
    "    for i,j in zip(y_pred,y):\n",
    "        if i==j:\n",
    "            noofcorrect+=1\n",
    "    return noofcorrect/len(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4a82354-963b-4424-95a6-a6c8f1129ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8957654723127035"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae352b54-744b-4d8e-a47b-ef76b68d3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion - LR and neural network performs best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
